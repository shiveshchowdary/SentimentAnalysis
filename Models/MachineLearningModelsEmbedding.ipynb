{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70325f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/shiveshkodali/Desktop/GitProjects/SentimentAnalysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a4c1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30c22af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_path+'Data/train.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ffb8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = list(data['Phrase'])\n",
    "labels = list(data['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "304c2909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return ''.join(char for char in text if char not in string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbb8628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shiveshkodali/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b743569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_special_characters_and_numbers(text):\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2846618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 156060/156060 [00:00<00:00, 636600.76it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = [remove_punctuation(text) for text in tqdm(documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aef017a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 156060/156060 [00:05<00:00, 28361.83it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = [remove_stopwords(text) for text in tqdm(documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c37993c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 156060/156060 [00:00<00:00, 2261778.02it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = [remove_special_characters_and_numbers(text) for text in tqdm(documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56ff33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [i.lower() for i in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fdd3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {documents[i]:labels[i] for i in range(len(documents)) if documents[i]!=''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4260dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = list(data_dict.keys())\n",
    "labels = list(data_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cb16f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:06, 58770.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {} # empty dictionary\n",
    "f = open('glove.6B.200d.txt', encoding=\"utf-8\")\n",
    "\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d082044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_vector(line):\n",
    "    emb_vec = np.zeros(200)\n",
    "    for word in line.split():\n",
    "        if word in embeddings_index.keys():\n",
    "            emb_vec+=(embeddings_index[word])\n",
    "    emb_vec = np.array(emb_vec)\n",
    "    return emb_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d68f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vec = embedding_vector('my name is shivesh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcc33f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98da9569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 84429/84429 [00:00<00:00, 323647.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(84429, 200)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "for line in tqdm(documents):\n",
    "    X.append(embedding_vector(line))\n",
    "    \n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aa7f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06480578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84429,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc4951db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "451977a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "# Create and train different machine learning models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(solver='lbfgs', max_iter=2000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\" : MultinomialNB()\n",
    "}\n",
    "\n",
    "def sentiment_analysis(model_name):\n",
    "    model = models[model_name]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "    print(report)\n",
    "    print(\"=\" * 50)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3eb3947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.58\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.11      0.18       746\n",
      "           1       0.44      0.25      0.32      3052\n",
      "           2       0.62      0.89      0.73      8386\n",
      "           3       0.50      0.36      0.41      3669\n",
      "           4       0.50      0.17      0.26      1033\n",
      "\n",
      "    accuracy                           0.58     16886\n",
      "   macro avg       0.50      0.36      0.38     16886\n",
      "weighted avg       0.54      0.58      0.53     16886\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee805108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Decision Tree\n",
      "Accuracy: 0.45\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.16      0.15       746\n",
      "           1       0.29      0.29      0.29      3052\n",
      "           2       0.62      0.62      0.62      8386\n",
      "           3       0.32      0.31      0.32      3669\n",
      "           4       0.22      0.22      0.22      1033\n",
      "\n",
      "    accuracy                           0.45     16886\n",
      "   macro avg       0.32      0.32      0.32     16886\n",
      "weighted avg       0.45      0.45      0.45     16886\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis('Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec060aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_vector(line,max_len):\n",
    "    emb_vec = []\n",
    "    for i in range(max_len):\n",
    "        words = line.split()\n",
    "        if i<len(words):\n",
    "            if word in embeddings_index.keys():\n",
    "                emb_vec.append(embeddings_index[word])\n",
    "            else:\n",
    "                emb_vec.append(np.zeros(200))\n",
    "        else:\n",
    "            emb_vec.append(np.zeros(200))\n",
    "    emb_vec = np.array(emb_vec)\n",
    "    return emb_vec.reshape(max_len*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae7baeb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vector('my name is shivesh', 5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef88fbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 84429/84429 [00:00<00:00, 338621.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(84429, 1000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "max_len = 5\n",
    "for line in tqdm(documents):\n",
    "    X.append(embedding_vector(line,max_len))\n",
    "    \n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd6458f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76c9d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "774b9f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67543, 1000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "879a6183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       746\n",
      "           1       0.00      0.00      0.00      3052\n",
      "           2       0.50      1.00      0.66      8386\n",
      "           3       0.00      0.00      0.00      3669\n",
      "           4       0.00      0.00      0.00      1033\n",
      "\n",
      "    accuracy                           0.50     16886\n",
      "   macro avg       0.10      0.20      0.13     16886\n",
      "weighted avg       0.25      0.50      0.33     16886\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiveshkodali/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shiveshkodali/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shiveshkodali/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis('Logistic Regression')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
